{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import git\n",
    "\n",
    "repo = git.Repo(Path(\".\").absolute(), search_parent_directories=True)\n",
    "ROOT = Path(repo.working_tree_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/scmjhl1/Documents/capturing-word-order\n"
     ]
    }
   ],
   "source": [
    "cd $ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "from tqdm.auto import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pos_bigram_ixs(ix_sents):\n",
    "    batch_size = ix_sents.shape[0]\n",
    "    sent_lengths = ix_sents.sign().sum(dim=1)\n",
    "    ixs = (\n",
    "        (torch.rand((batch_size,)) * (sent_lengths.float() - 1))\n",
    "        .floor()\n",
    "        .long()\n",
    "        .view(-1, 1)\n",
    "    )\n",
    "    return ix_sents[\n",
    "        torch.arange(batch_size).view(-1, 1), torch.cat((ixs, (ixs + 1)), dim=1),\n",
    "    ]\n",
    "\n",
    "\n",
    "def gen_neg_bigram_ixs(ix_sents):\n",
    "    batch_size, chunk_size = ix_sents.shape\n",
    "    sent_lengths = ix_sents.sign().sum(dim=1)\n",
    "    # ``distr_ixs1`` determines from where to sample the first index. \n",
    "    # All indices but the last one allows for combining with ``sent_lengths`` - 1 \n",
    "    # different second indices.\n",
    "    distr_ixs1 = (sent_lengths.view(-1, 1) - 1) * ix_sents.sign()\n",
    "    # The last index allows for combining with ``sent_lengths`` different second indices\n",
    "    distr_ixs1[torch.arange(batch_size), sent_lengths - 1] = sent_lengths\n",
    "    ixs1 = Categorical(distr_ixs1.float()).sample().view(-1, 1)\n",
    "    # ``distr_ixs2`` determines from where to sample the second index.\n",
    "    # The boundary case is resolved by initializing  ``distr_ixs2`` with\n",
    "    # one extra column and then removing it later.\n",
    "    distr_ixs2 = torch.zeros((batch_size, chunk_size + 1))\n",
    "    distr_ixs2[:, :-1] = ix_sents.sign()\n",
    "    # The indices that lead to positive bigrams are avoided by setting\n",
    "    # the corresponding value in ``distribution`` to zero.\n",
    "    distr_ixs2[torch.arange(batch_size).view(-1, 1), ixs1 + 1] = 0\n",
    "    distr_ixs2 = distr_ixs2[:, :-1]\n",
    "    ixs2 = Categorical(distr_ixs2).sample().view(-1, 1)\n",
    "    return ix_sents[\n",
    "        torch.arange(batch_size).view(-1, 1), torch.cat((ixs1, ixs2), dim=1)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "from src.misc import WV, BigramEncoder, load_wiki, process_word_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAST_TEXT = ROOT / \"data/raw/crawl-300d-2M.vec\"\n",
    "word2index, word_vecs = process_word_vecs(FAST_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = load_wiki(max_len=25)\n",
    "# Note that the word embeddings are normalize.\n",
    "wv = WV(F.normalize(word_vecs), word2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_sents, sent_lengths = wv.to_ix_sents(\n",
    "    sentences, return_sent_lengths=True, adjust=True\n",
    ")\n",
    "perm = torch.randperm(len(ix_sents))\n",
    "ix_sents = ix_sents[perm]\n",
    "sent_lengths = sent_lengths[perm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Bigram Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_bigram_encoder(bigram_encoder_name, ix_sents, batch_size, smoke_test=False):\n",
    "    if smoke_test:\n",
    "        ix_sents = ix_sents[:1000]\n",
    "    bigram_encoder = BigramEncoder(bigram_encoder_name)\n",
    "    cos = nn.CosineSimilarity(dim=2)\n",
    "    result_comparison = torch.tensor([]).bool()\n",
    "    result_pos_dist = torch.tensor([]).float()\n",
    "    result_neg_dist = torch.tensor([]).float()\n",
    "    for i in trange(0, len(ix_sents), batch_size):\n",
    "        vsents = wv.vecs[ix_sents[i : i + batch_size]]\n",
    "        bigram_vsents = bigram_encoder(vsents)\n",
    "        bigram_sentvecs = bigram_vsents.sum(1, keepdim=True)\n",
    "        pos_bigram_ixs = gen_pos_bigram_ixs(ix_sents[i : i + batch_size])\n",
    "        neg_bigram_ixs = gen_neg_bigram_ixs(ix_sents[i : i + batch_size])\n",
    "        pos_bigram_vecs = bigram_encoder(wv.vecs[pos_bigram_ixs])\n",
    "        neg_bigram_vecs = bigram_encoder(wv.vecs[neg_bigram_ixs])\n",
    "\n",
    "        comparison = cos(bigram_vsents, bigram_sentvecs).min(dim=1, keepdim=True).values\n",
    "        pos_dist = cos(pos_bigram_vecs, bigram_sentvecs)\n",
    "        neg_dist = cos(neg_bigram_vecs, bigram_sentvecs)\n",
    "\n",
    "        result_comparison = torch.cat(\n",
    "            (result_comparison, comparison > neg_dist,), dim=0\n",
    "        )\n",
    "        result_pos_dist = torch.cat((result_pos_dist, pos_dist), dim=0)\n",
    "        result_neg_dist = torch.cat((result_neg_dist, neg_dist), dim=0)\n",
    "    return result_comparison, result_pos_dist, result_neg_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_table_1(batch_size, smoke_test=False):\n",
    "    for bigram_encoder_name in [\"mult\", \"tanh\", \"tanh10\", \"sign\"]:\n",
    "        result_comparison, _, _ = analyze_bigram_encoder(\n",
    "            bigram_encoder_name, ix_sents, batch_size, smoke_test\n",
    "        )\n",
    "        print(bigram_encoder_name, result_comparison.float().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f29b573d70741aba6869cd7f860e989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mult 0.004999999888241291\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "907c4a2b51f041c8b08882167001c107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tanh 0.1469999998807907\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07546c04f42b4e87ada06dbaf6e406cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tanh10 0.20600000023841858\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df47fcf156c2411dbe9148bada7188b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sign 0.4230000078678131\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "batch_size = 100000\n",
    "generate_table_1(batch_size, smoke_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a253bc36bb4c6a92f9cbe42776cb3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "batch_size = 100000\n",
    "result_comparison, result_pos_dist, result_neg_dist = analyze_bigram_encoder(\n",
    "    \"sign\", ix_sents, batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(result_pos_dist.numpy(), bins=1000, alpha=0.5)\n",
    "plt.hist(result_neg_dist.numpy(), bins=1000, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ``gen_pos_examples`` and ``gen_neg_examples``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test whether all possible positive and negative examples are generated correctly and their counts are distributed evely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_example_generators():\n",
    "    n_rows = 1000000\n",
    "    ix_sents = torch.tensor([[1, 2, 3, 0, 0], [4, 5, 6, 7, 8]]).repeat(n_rows // 2, 1)\n",
    "    sent_lengths = ix_sents.sign().sum(dim=1)\n",
    "\n",
    "    pos_bigram_ixs = gen_pos_bigram_ixs(ix_sents)\n",
    "    neg_bigram_ixs = gen_neg_bigram_ixs(ix_sents)\n",
    "\n",
    "    counter_pos_examples = Counter(tuple(pair) for pair in pos_bigram_ixs.numpy())\n",
    "    counter_neg_examples = Counter(tuple(pair) for pair in neg_bigram_ixs.numpy())\n",
    "\n",
    "    pos_examples_1 = {(1, 2), (2, 3)}\n",
    "    neg_examples_1 = set(product([1, 2, 3], repeat=2)) - pos_examples_1\n",
    "    pos_examples_2 = {(4, 5), (5, 6), (6, 7), (7, 8)}\n",
    "    neg_examples_2 = set(product([4, 5, 6, 7, 8], repeat=2)) - pos_examples_2\n",
    "\n",
    "    total_counts_pos_examples_1 = sum(\n",
    "        [counter_pos_examples[pair] for pair in pos_examples_1]\n",
    "    )\n",
    "    total_counts_neg_examples_1 = sum(\n",
    "        [counter_neg_examples[pair] for pair in neg_examples_1]\n",
    "    )\n",
    "    total_counts_pos_examples_2 = sum(\n",
    "        [counter_pos_examples[pair] for pair in pos_examples_2]\n",
    "    )\n",
    "    total_counts_neg_examples_2 = sum(\n",
    "        [counter_neg_examples[pair] for pair in neg_examples_2]\n",
    "    )\n",
    "\n",
    "    total_counts_pos_examples_1 == total_counts_neg_examples_1 == n_rows // 2\n",
    "    total_counts_pos_examples_2 == total_counts_neg_examples_1 == n_rows // 2\n",
    "\n",
    "    assert sum(counter_pos_examples.values()) == n_rows\n",
    "\n",
    "    assert (\n",
    "        np.std(\n",
    "            [\n",
    "                counter_pos_examples[pair] / total_counts_pos_examples_1\n",
    "                for pair in pos_examples_1\n",
    "            ]\n",
    "        )\n",
    "        < 0.01\n",
    "    )\n",
    "\n",
    "    assert (\n",
    "        np.std(\n",
    "            [\n",
    "                counter_pos_examples[pair] / total_counts_neg_examples_1\n",
    "                for pair in neg_examples_1\n",
    "            ]\n",
    "        )\n",
    "        < 0.01\n",
    "    )\n",
    "\n",
    "    assert (\n",
    "        np.std(\n",
    "            [\n",
    "                counter_pos_examples[pair] / total_counts_pos_examples_2\n",
    "                for pair in pos_examples_2\n",
    "            ]\n",
    "        )\n",
    "        < 0.01\n",
    "    )\n",
    "\n",
    "    assert (\n",
    "        np.std(\n",
    "            [\n",
    "                counter_neg_examples[pair] / total_counts_neg_examples_2\n",
    "                for pair in pos_examples_2\n",
    "            ]\n",
    "        )\n",
    "        < 0.01\n",
    "    )\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_example_generators()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
