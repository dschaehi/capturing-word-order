{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import git\n",
    "\n",
    "repo = git.Repo(Path(\".\").absolute(), search_parent_directories=True)\n",
    "ROOT = Path(repo.working_tree_dir)\n",
    "SRC = ROOT / \"src\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $SRC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import trange\n",
    "\n",
    "from analyze_bigram_encoders import (\n",
    "    gen_neg_bigram_ixs,\n",
    "    gen_pos_bigram_ixs,\n",
    "    plot_bigram_norm,\n",
    "    plot_result,\n",
    "    plot_uniformity,\n",
    ")\n",
    "from misc import WV, BigramEncoder, load_wiki, process_word_vecs\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAST_TEXT = ROOT / \"data/raw/crawl-300d-2M.vec\"\n",
    "word2index, word_vecs = process_word_vecs(FAST_TEXT)\n",
    "\n",
    "# Note that the word embeddings are normalized.\n",
    "wv = WV(F.normalize(word_vecs), word2index)\n",
    "# wv = WV(word_vecs, word2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = load_wiki(max_len=25)\n",
    "\n",
    "ix_sents, sent_lengths = wv.to_ix_sents(\n",
    "    sentences, filter_stopwords=False, return_sent_lengths=True, adjust=True\n",
    ")\n",
    "perm = torch.randperm(len(ix_sents))\n",
    "ix_sents = ix_sents[perm]\n",
    "sent_lengths = sent_lengths[perm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) $f_{\\odot}(\\mathbf{w}, \\mathbf{w'})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(\"mult\", wv, ix_sents, 1000, average_comparison=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) $f_1(\\mathbf{w}, \\mathbf{w'})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(\"tanh\", wv, ix_sents, 1000, average_comparison=True, add_legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) $f_{10}(\\mathbf{w}, \\mathbf{w'})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(\"tanh10\", wv, ix_sents, 1000, average_comparison=True, add_legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) $f_{\\infty}(\\mathbf{w}, \\mathbf{w'})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(\"sign\", wv, ix_sents, 1000, average_comparison=True, add_legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) $f_{T}(\\mathbf{w}, \\mathbf{w'})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(\n",
    "    \"T\",\n",
    "    wv,\n",
    "    ix_sents,\n",
    "    100,\n",
    "    average_comparison=True,\n",
    "    model_path=\"../models/bigram_nn_wiki_train_1000000.pth\",\n",
    "    add_legend=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) The distribution of $\\lVert f(\\mathbf{w}, \\mathbf{w'}) \\rVert$ with $(w, w') \\in B(S)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bigram_norm(\n",
    "    wv=wv,\n",
    "    ix_sents=ix_sents,\n",
    "    batch_size=1000,\n",
    "    outdir=ROOT / \"paper/img\",\n",
    "    model_path=\"../models/bigram_nn_wiki_train_1000000.pth\",\n",
    "    seed=0,\n",
    "    add_legend=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) $(w, w')$ are random word pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_uniformity(\n",
    "    word_pair=\"random\",\n",
    "    wv=wv,\n",
    "    ix_sents=ix_sents,\n",
    "    batch_size=1000,\n",
    "    outdir=ROOT / \"paper/img\",\n",
    "    model_path=\"../models/bigram_nn_wiki_train_1000000.pth\",\n",
    "    seed=0,\n",
    "    add_legend=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(g) $(w, w')$ are bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_uniformity(\n",
    "    word_pair=\"bigram\",\n",
    "    wv=wv,\n",
    "    ix_sents=ix_sents,\n",
    "    batch_size=1000,\n",
    "    outdir=ROOT / \"paper/img\",\n",
    "    model_path=\"../models/bigram_nn_wiki_train_1000000.pth\",\n",
    "    seed=0,\n",
    "    add_legend=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
