{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import git\n",
    "\n",
    "repo = git.Repo(Path(\".\").absolute(), search_parent_directories=True)\n",
    "ROOT = Path(repo.working_tree_dir)\n",
    "SRC = ROOT / \"src\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $SRC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_candidate_sents = nn.get_candidate_sents\n",
    "gen_bvs_i2b = nn.gen_bvs_i2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_unigram_sents = sr.ngram_sents(sents, 1, markers=False)\n",
    "original_bigram_sents = sr.ngram_sents(sents, 2, markers=True)\n",
    "original_trigram_sents = sr.ngram_sents(sents, 3, markers=True)\n",
    "\n",
    "unigram_sent_vecs = sr.ngram_sent_vecs(\n",
    "    original_unigram_sents, disc.disc, word_vecs, word2index, 1\n",
    ")\n",
    "trigram_sent_vecs = sr.ngram_sent_vecs(\n",
    "    original_trigram_sents, disc.disc, word_vecs, word2index, 3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct Unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce the Size of the Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 40,000 words close to the sentence cover in 99% of the cases all the unigrams in the sentence. (Evaluated on the validation set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs_full = pickle.load(open(WORD_VECTORS, \"rb\"))\n",
    "word2index_full = pickle.load(open(WORD2INDEX, \"rb\"))\n",
    "word_vecs = normalize(word_vecs_full[[word2index_full[word] for word in word2index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 100\n",
    "TOP_N = 40000\n",
    "indices = np.argsort(word_vecs @ unigram_sent_vecs[i])[::-1][:TOP_N]\n",
    "len(set(original_unigram_sents[i]) & set(index2word[index] for index in indices)) / len(\n",
    "    set(original_unigram_sents[i])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP_N = 40000\n",
    "\n",
    "# reconstructed_unigram_sents = []\n",
    "# for unigram_sent_vec in tqdm(unigram_sent_vecs):\n",
    "#     indices = np.argsort(word_vecs @ unigram_sent_vec)[::-1][:TOP_N]\n",
    "#     words = [index2word[index] for index in indices]\n",
    "#     reconstructed_unigram_sents.append(\n",
    "#         sr.reconstruct(\n",
    "#             unigram_sent_vec, word_vecs[indices], dict(enumerate(words)), solver=\"bp\"\n",
    "#         )\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = sr.make_file_name(1, sents)\n",
    "# with open(RESULTS / file_name, \"wb\") as f:\n",
    "#     pickle.dump(reconstructed_unigram_sents, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = sr.make_file_name(1, sents)\n",
    "\n",
    "if (RESULTS / file_name).exists():\n",
    "    with open(RESULTS / file_name, \"rb\") as f:\n",
    "        reconstructed_unigram_sents = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr.accuracy(original_unigram_sents, reconstructed_unigram_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(original_unigram_sents)):\n",
    "#     if original_unigram_sents[i] != reconstructed_unigram_sents[i]:\n",
    "#         print(i)\n",
    "#         print(original_unigram_sents[i] - reconstructed_unigram_sents[i])\n",
    "#         print(reconstructed_unigram_sents[i] - original_unigram_sents[i])\n",
    "#         print(\"==================\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
